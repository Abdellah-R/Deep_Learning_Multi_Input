{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 16:04:25.209835: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 16:04:25.376892: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 16:04:25.379251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 16:04:28.392380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/apprenant/Documents/Deep_Learning_Multi_Input/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_csv_img/Flipkart/flipkart_com-ecommerce_sample_1050.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   uniq_id                  1050 non-null   object \n",
      " 1   crawl_timestamp          1050 non-null   object \n",
      " 2   product_url              1050 non-null   object \n",
      " 3   product_name             1050 non-null   object \n",
      " 4   product_category_tree    1050 non-null   object \n",
      " 5   pid                      1050 non-null   object \n",
      " 6   retail_price             1049 non-null   float64\n",
      " 7   discounted_price         1049 non-null   float64\n",
      " 8   image                    1050 non-null   object \n",
      " 9   is_FK_Advantage_product  1050 non-null   bool   \n",
      " 10  description              1050 non-null   object \n",
      " 11  product_rating           1050 non-null   object \n",
      " 12  overall_rating           1050 non-null   object \n",
      " 13  brand                    712 non-null    object \n",
      " 14  product_specifications   1049 non-null   object \n",
      "dtypes: bool(1), float64(2), object(12)\n",
      "memory usage: 116.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_category_tree'] = df['product_category_tree'].apply(lambda x : x.split(\" >> \")[0][2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Home Furnishing\n",
       "1             Baby Care\n",
       "2             Baby Care\n",
       "3       Home Furnishing\n",
       "4       Home Furnishing\n",
       "             ...       \n",
       "1045          Baby Care\n",
       "1046          Baby Care\n",
       "1047          Baby Care\n",
       "1048          Baby Care\n",
       "1049          Baby Care\n",
       "Name: category, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'product_category_tree': 'category'}, inplace=True)\n",
    "df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Key Features of Elegance Polyester Multicolor ...\n",
       "1       Specifications of Sathiyas Cotton Bath Towel (...\n",
       "2       Key Features of Eurospa Cotton Terry Face Towe...\n",
       "3       Key Features of SANTOSH ROYAL FASHION Cotton P...\n",
       "4       Key Features of Jaipur Print Cotton Floral Kin...\n",
       "                              ...                        \n",
       "1045    Oren Empower Extra Large Self Adhesive Sticker...\n",
       "1046    Wallmantra Large Vinyl Sticker Sticker (Pack o...\n",
       "1047    Buy Uberlyfe Extra Large Pigmented Polyvinyl F...\n",
       "1048    Buy Wallmantra Medium Vinyl Sticker Sticker fo...\n",
       "1049    Buy Uberlyfe Large Vinyl Sticker for Rs.595 on...\n",
       "Name: description, Length: 1050, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.52MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 51.5kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 874kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 440M/440M [00:39<00:00, 11.1MB/s] \n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "27/27 [==============================] - 1026s 35s/step - loss: 1.8412 - accuracy: 0.2917 - val_loss: 1.5488 - val_accuracy: 0.5905\n",
      "Epoch 2/3\n",
      "27/27 [==============================] - 1459s 55s/step - loss: 1.4159 - accuracy: 0.6250 - val_loss: 1.0824 - val_accuracy: 0.7762\n",
      "Epoch 3/3\n",
      "27/27 [==============================] - 922s 34s/step - loss: 0.9366 - accuracy: 0.8119 - val_loss: 0.6401 - val_accuracy: 0.8857\n",
      "7/7 [==============================] - 79s 10s/step\n",
      "Précision du modèle : 0.8857142857142857\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                 Baby Care       0.71      0.63      0.67        27\n",
      "  Beauty and Personal Care       0.94      0.76      0.84        21\n",
      "                 Computers       0.95      1.00      0.97        38\n",
      "Home Decor & Festive Needs       0.85      0.97      0.91        30\n",
      "           Home Furnishing       0.86      0.86      0.86        35\n",
      "          Kitchen & Dining       0.86      0.92      0.89        26\n",
      "                   Watches       1.00      0.97      0.98        33\n",
      "\n",
      "                  accuracy                           0.89       210\n",
      "                 macro avg       0.88      0.87      0.87       210\n",
      "              weighted avg       0.89      0.89      0.88       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# - Encoder les catégories en numériques\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['category'])\n",
    "\n",
    "# Tokenisation avec le tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_texts = [tokenizer.encode(text, add_special_tokens=True, max_length=128, truncation=True) for text in df['description']]\n",
    "\n",
    "# Padding des séquences\n",
    "max_len = max(len(text) for text in tokenized_texts)\n",
    "input_ids = np.array([text + [0] * (max_len - len(text)) for text in tokenized_texts])\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_ids, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer le modèle BERT\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Compiler le modèle\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Évaluer le modèle\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred.logits, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "report = classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_)\n",
    "\n",
    "print(\"Précision du modèle :\", accuracy)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
